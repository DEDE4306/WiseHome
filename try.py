import asyncio
import json
import re
import os

from typing import TypedDict, Annotated, Optional, Literal, List
from dotenv import load_dotenv

from langchain.agents import AgentExecutor, create_structured_chat_agent
from langchain.chat_models import init_chat_model
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.tools import BaseTool
from langchain_mcp_adapters.client import MultiServerMCPClient

from langgraph.graph import add_messages, StateGraph, END
from langgraph.prebuilt import create_react_agent

from db.chats import get_session_history
from template import system_template

load_dotenv()
api_key = os.getenv("BAILIAN_API_KEY")

# åˆå§‹åŒ–æ¨¡å‹
model = init_chat_model(
    "qwen3-0.6b",
    model_provider="openai",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=api_key,
    temperature=1,
    model_kwargs={"extra_body": {"enable_thinking": False}}
)

router_template = """ä½ æ˜¯è·¯ç”±åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·æ„å›¾ï¼Œè¾“å‡º JSONï¼š

é‡è¦è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·åªæ˜¯æ‰“æ‹›å‘¼/é—²èŠï¼ˆå¦‚"ä½ å¥½"ã€"è°¢è°¢"ã€"åœ¨å—"ï¼‰ï¼Œè¾“å‡ºï¼š{{"type": "chat", "response": "å…·ä½“çš„å›å¤"}}
2. å¦‚æœæ˜¯ä»»åŠ¡æŒ‡ä»¤ï¼Œæ‹†åˆ†ä¸ºç‹¬ç«‹å­ä»»åŠ¡å¹¶åˆ†ç±»ï¼š
   - smart_home_controlï¼šæ§åˆ¶è®¾å¤‡åŠ¨ä½œï¼ˆå¼€/å…³/è°ƒèŠ‚ç¯/ç©ºè°ƒ/éŸ³å“/æ’­æ”¾éŸ³ä¹ç­‰ï¼‰
   - query_infoï¼šè·å–ä¿¡æ¯ï¼ˆæŸ¥å¤©æ°”/è®¾å¤‡çŠ¶æ€/æ—¶é—´/åˆ—è¡¨ç­‰ï¼‰
3. è¾“å‡ºæ ¼å¼ï¼š{{"type": "task", "sub_tasks": [{{"task": "å­ä»»åŠ¡å†…å®¹", "category": "ç±»åˆ«"}}]}}

è§„åˆ™ï¼š
1. å¦‚æœæ¶‰åŠâ€œæ‰“å¼€/å…³é—­/è°ƒèŠ‚â€è®¾å¤‡ â†’ category: smart_home_control
2. å¦‚æœæ¶‰åŠâ€œæŸ¥è¯¢/è·å–/çŠ¶æ€â€ â†’ category: query_info
3. å¤šä¸ªæˆ¿é—´åˆ†åˆ«æ§åˆ¶ â†’ æ‹†æˆå¤šä¸ª smart_home_control ä»»åŠ¡

ç¤ºä¾‹ï¼š
- åªæ˜¯æ‰“æ‹›å‘¼ï¼Œé—²èŠ
è¾“å…¥ï¼šä½ å¥½
è¾“å‡ºï¼š{{"type": "chat", "response": "ä½ å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¶å±…åŠ©æ‰‹ï¼Œå¯ä»¥å¸®ä½ æ§åˆ¶è®¾å¤‡æˆ–æŸ¥è¯¢ä¿¡æ¯ã€‚"}}

- æŸ¥è¯¢ä¿¡æ¯
è¾“å…¥ï¼šç°åœ¨å‡ ç‚¹äº†
è¾“å‡ºï¼š{{"type": "task", "sub_tasks": [{{"task":"æŸ¥è¯¢å½“å‰æ—¶é—´", "category": "query_info"}}]}}

è¾“å…¥ï¼šä»Šå¤©å¤©æ°”å¦‚ä½•
è¾“å‡ºï¼š{{"type": "task", "sub_tasks": [{{"task":"æŸ¥è¯¢å½“å‰å¤©æ°”", "category": "query_info"}}]}}

- è¾“å…¥å¤šç§æ“ä½œ
è¾“å…¥ï¼šæ‰“å¼€å®¢å…ç¯ï¼ŒæŸ¥è¯¢å§å®¤ç©ºè°ƒæ¸©åº¦
è¾“å‡ºï¼š{{"type": "task", "sub_tasks": [{{"task": "æ‰“å¼€å®¢å…ç¯", "category": "smart_home_control"}}, 
{{"task": "æŸ¥è¯¢å§å®¤ç©ºè°ƒæ¸©åº¦", "category": "query_info"}}]}}

åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_template),
    MessagesPlaceholder("chat_history"),
    ("human", "{input} {agent_scratchpad}"),
])


class AgentState(TypedDict):
    """çŠ¶æ€å®šä¹‰"""
    messages: Annotated[list, add_messages]
    sub_tasks: List[dict]  # [{"task": "xxx", "category": "xxx"}]
    current_idx: int  # å½“å‰æ‰§è¡Œåˆ°ç¬¬å‡ ä¸ªä»»åŠ¡
    is_chat: bool  # æ˜¯å¦ä¸ºæ™®é€šå¯¹è¯
    input: str  # åŸå§‹ç”¨æˆ·è¾“å…¥

_tools_cache = None

async def load_mcp_tools():
    """åŠ è½½ MCP å·¥å…·"""
    global _tools_cache
    if _tools_cache is None:
        client = MultiServerMCPClient(
            {
                "wisehome": {
                    "url": "http://localhost:8001/sse",
                    "transport": "sse",
                }
            }
        )
        _tools_cache = await client.get_tools()
    return _tools_cache


def extract_json(text: str) -> dict:
    """ä»æ–‡æœ¬ä¸­æå– JSON"""
    text = text.strip()

    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(0))
        except Exception as e:
            print(f"JSON è§£æå¤±è´¥ï¼š{e}")

    return {}

async def llm_route(user_input: str, context_info: str = "") -> dict:
    """ä½¿ç”¨ LLM åˆ¤æ–­æ„å›¾å¹¶æ‹†åˆ†ä»»åŠ¡"""
    full_input = f"{user_input}\n{context_info}" if context_info else user_input   # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œé™„åŠ åˆ°è¾“å…¥ä¸­

    route_prompt = ChatPromptTemplate.from_messages([
        ("system", router_template),
        ("user", "{input}")
    ])

    response = await (route_prompt | model).ainvoke({"input": full_input})
    result = extract_json(response.content)

    if not result:
        print("è·¯ç”±è§£æå¤±è´¥ï¼Œé»˜è®¤ä¸ºæ™®é€šå¯¹è¯")
        return {"type": "chat", "response": "æŠ±æ­‰ï¼Œæˆ‘æ²¡ç†è§£ä½ çš„æ„æ€ã€‚"}

    result_type = result.get("type", "chat")

    if result_type == "task" and not result.get("sub_tasks"):
        print("ä»»åŠ¡æ‹†åˆ†ä¸ºç©ºï¼Œé™çº§ä¸ºå¯¹è¯")
        return {"type": "chat", "response": "è¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"}

    return result


async def agent_router(state: AgentState) -> AgentState:
    """è·¯ç”±èŠ‚ç‚¹ï¼šåˆ¤æ–­æ„å›¾å¹¶åˆå§‹åŒ–çŠ¶æ€"""
    user_input = state["input"]
    context_info = state.get("context_info", "")

    route_result = await llm_route(user_input, context_info)

    result_type = route_result.get("type", "chat")

    print(f"æ„å›¾è¯†åˆ«ï¼š{result_type}")

    if result_type == "chat":
        response = route_result.get("response", "ä½ å¥½ï¼")
        print(f"å¯¹è¯å›å¤ï¼š{response}")
        return {
            **state,
            "is_chat": True,
            "sub_tasks": [],
            "current_idx": 0,
            "messages": [AIMessage(content=response)],
        }
    else:
        sub_tasks = route_result.get("sub_tasks", [])
        print(f"ä»»åŠ¡æ‹†åˆ†ï¼š{json.dumps(sub_tasks, ensure_ascii=False)}")
        return {
            **state,
            "is_chat": False,
            "sub_tasks": sub_tasks,
            "current_idx": 0,
            "messages": state.get("messages", [])  # ä¿ç•™å·²æœ‰æ¶ˆæ¯
        }


def route_decision(state: AgentState) -> Literal["smart_home_control", "query_info", "mixed", "re_route", "end"]:
    """å†³ç­–å‡½æ•°ï¼šæ ¹æ®å½“å‰ä»»åŠ¡çš„ category è·¯ç”±"""
    if state.get("is_chat", False):
        return "end"

    current_idx = state.get("current_idx", 0)
    sub_tasks = state.get("sub_tasks", [])

    if current_idx >= len(sub_tasks):
        return "end"

    current_task = sub_tasks[current_idx]
    category = current_task.get("category", "query_info")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è·¯ç”±
    if current_task.get("needs_re_route", False):
        print(f"éœ€è¦é‡æ–°è·¯ç”± (ä»»åŠ¡ {current_idx + 1}/{len(sub_tasks)})")
        return "re_route"

    print(f"è·¯ç”±åˆ°: {category} (ä»»åŠ¡ {current_idx + 1}/{len(sub_tasks)})")

    return category


async def filter_tools_by_category(all_tools: List[BaseTool], category: str) -> List[BaseTool]:
    """æ ¹æ®ç±»åˆ«ç­›é€‰å·¥å…·"""
    if category == "smart_home_control":
        keywords = ["turn", "set", "open", "close", "switch", "è°ƒèŠ‚", "å¼€", "å…³", "è®¾ç½®", "æ’­æ”¾", "play", "stop", "éŸ³ä¹"]
    elif category == "query_info":
        keywords = ["get", "query", "status", "weather", "list", "æŸ¥è¯¢", "è·å–", "çŠ¶æ€", "ä¿¡æ¯", "rooms", "room"]
    else:
        return all_tools

    filtered_tools = [
        tool for tool in all_tools
        if any(kw in tool.name.lower() or kw in tool.description.lower() for kw in keywords)
    ]

    return filtered_tools if filtered_tools else all_tools


# å…¨å±€ç¼“å­˜ï¼šcategory -> (agent, agent_executor)
_agent_cache = {}
_agent_cache_lock = asyncio.Lock()

async def get_agent_executor_for_category(category: str, model, tools, prompt):
    """è·å–æŒ‡å®šç±»åˆ«çš„ agent executorï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    global _agent_cache

    if category in _agent_cache:
        return _agent_cache[category]

    async with _agent_cache_lock:
        # åŒé‡æ£€æŸ¥ï¼Œé˜²æ­¢ç«æ€
        if category in _agent_cache:
            return _agent_cache[category]

        # åˆ›å»º agent å’Œ executor
        agent = create_structured_chat_agent(model, tools=tools, prompt=prompt)
        agent_executor = AgentExecutor.from_agent_and_tools(
            agent=agent,
            tools=tools,
            verbose=True,
            handle_parsing_errors=True,
        )

        # åŒ…è£…æˆå¸¦è®°å¿†çš„ Runnable
        agent_with_memory = RunnableWithMessageHistory(
            agent_executor,
            get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
        )

        # ç¼“å­˜
        _agent_cache[category] = agent_with_memory
        return agent_with_memory


async def execute_simple_task(state: AgentState, category: str) -> AgentState:
    """æ‰§è¡Œç®€å•ä»»åŠ¡ï¼ˆå•ä¸€æŸ¥è¯¢æˆ–æ§åˆ¶ï¼‰"""
    current_idx = state["current_idx"]
    sub_tasks = state["sub_tasks"]
    current_task = sub_tasks[current_idx]
    task_content = current_task["task"]

    print(f"æ‰§è¡Œä»»åŠ¡ {current_idx + 1}: {task_content} [{category}]")

    all_tools = await load_mcp_tools()
    filtered_tools = await filter_tools_by_category(all_tools, category)

    tool_names = [t.name for t in filtered_tools]
    print(f"ä½¿ç”¨å·¥å…·: {', '.join(tool_names)}")

    agent_with_memory = await get_agent_executor_for_category(category, model, filtered_tools, prompt)

    try:
        response = await agent_with_memory.ainvoke(
            {"input": task_content},
            config={"configurable": {"thread_id": "2", "session_id": "user_1"}}
        )
        result = response.get("output", "æ‰§è¡Œå®Œæˆ")

        print(f"ä»»åŠ¡å®Œæˆ: {result}")

        return {
            **state,
            "messages": [AIMessage(content=result)],
            "current_idx": current_idx + 1
        }
    except Exception as e:
        print(f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}")
        return {
            **state,
            "messages": [AIMessage(content=f"å¤±è´¥: {str(e)}")],
            "current_idx": current_idx + 1
        }



async def smart_home_agent(state: AgentState) -> AgentState:
    """æ™ºèƒ½å®¶å±…æ§åˆ¶æ‰§è¡Œå™¨"""
    return await execute_simple_task(state, "smart_home_control")


async def query_info_agent(state: AgentState) -> AgentState:
    """ä¿¡æ¯æŸ¥è¯¢æ‰§è¡Œå™¨"""
    return await execute_simple_task(state, "query_info")

async def create_workflow():
    """æ„å»º Workflow"""
    workflow = StateGraph(AgentState)

    workflow.add_node("router", agent_router)
    workflow.add_node("smart_home_control", smart_home_agent)
    workflow.add_node("query_info", query_info_agent)

    workflow.set_entry_point("router")

    workflow.add_conditional_edges(
        "router",
        route_decision,
        {
            "smart_home_control": "smart_home_control",
            "query_info": "query_info",
            "end": END
        }
    )

    workflow.add_conditional_edges(
        "smart_home_control",
        route_decision,
        {
            "smart_home_control": "smart_home_control",
            "query_info": "query_info",
            "end": END
        }
    )

    workflow.add_conditional_edges(
        "query_info",
        route_decision,
        {
            "smart_home_control": "smart_home_control",
            "query_info": "query_info",
            "end": END
        }
    )


    return workflow.compile()


async def main():
    try:
        print("MCP æ™ºèƒ½å®¶å±…ç³»ç»Ÿå·²è¿æ¥ï¼")
        print("ç¤ºä¾‹ï¼š'æ‰“å¼€å®¢å…ç¯'ï¼Œ'æŸ¥è¯¢å¤©æ°”'")

        workflow = await create_workflow()

        while True:
            user_input = input("\nä½ : ").strip()

            if user_input.lower() in {"exit", "quit", "é€€å‡º"}:
                print("ğŸ‘‹ å†è§ï¼")
                break

            if not user_input:
                continue

            response = await workflow.ainvoke(
                {"input": user_input, "context_info": ""},
                config={"configurable": {"thread_id": "2", "session_id": "user_1"}}
            )

            messages = response.get("messages", [])
            if messages:
                print("\nAI:")
                for msg in messages:
                    if hasattr(msg, "content"):
                        print(f"{msg.content}")
            else:
                print("AI: (æ— å›å¤)")

    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nå·²é€€å‡ºã€‚")


